{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data as pandas dataframe, create feature and label data before splitting train and test \n",
    "fname=\"mills_sph_d50_fs.csv\"\n",
    "data= pd.read_csv(fname,sep= \",\")\n",
    "ncols=len(data.columns)\n",
    "X= data.iloc[:,:ncols-1]\n",
    "y= data.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a model and find the best threshold based on TPR-FPR\n",
    "\n",
    "class ClassifierWithThreshold:\n",
    "\n",
    "    def __init__(self,model):\n",
    "        \n",
    "        self.model=model\n",
    "\n",
    "    def predict(self, X, threshold=None):\n",
    "        if threshold == None: # If no threshold passed in, simply call the base class predict, effectively threshold=0.5\n",
    "            return self.model.predict(X)\n",
    "        else:\n",
    "            y_scores = self.model.predict_proba(X)[:, 1]\n",
    "            y_pred_with_threshold = (y_scores >= threshold).astype(int)\n",
    "\n",
    "            return y_pred_with_threshold\n",
    "    \n",
    "    def threshold_from_optimal_f_score(self, X, y):\n",
    "        y_scores = self.model.predict_proba(X)[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(y, y_scores) \n",
    "\n",
    "        optimal_idx = np.argmax(tpr-fpr)\n",
    "        \n",
    "        return thresholds[optimal_idx], tpr[optimal_idx] - fpr[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Generation\n",
    "\n",
    "def ClassificationMethod(X_train, y_train,X_test,y_test,model_name:str, cv:int=5, scoring:str=\"accuracy\"):\n",
    "\n",
    "    if model_name==\"LogisticRegression\":\n",
    "                name=\"lr\"\n",
    "                grid_param = {\n",
    "                'penalty': [\"l1\",\"l2\",\"elastic\"],\n",
    "                'C': [10**-3,10**-2,10**-1,1,10,100],\n",
    "                \"class_weight\":[{1:1.1},{1:1.2},{1:1.2},{1:1.3},{1:1.4},{1:1.5}]\n",
    "                }\n",
    "                logisticClassifier=LogisticRegression()\n",
    "\n",
    "                gd_sr = GridSearchCV(estimator=logisticClassifier,\n",
    "                            param_grid=grid_param,\n",
    "                            scoring=scoring,\n",
    "                            cv=cv,\n",
    "                            n_jobs=-1)\n",
    "        \n",
    "                gd_sr.fit(X_train, y_train)\n",
    "                best_parameters = gd_sr.best_params_\n",
    "               \n",
    "                logisticClassifier= LogisticRegression(penalty=best_parameters[\"penalty\"],C=best_parameters[\"C\"],class_weight=best_parameters['class_weight'])\n",
    "                logisticClassifier.fit(X_train, y_train)\n",
    "  \n",
    "                model= logisticClassifier\n",
    "                \n",
    "                logisticClassifier=ClassifierWithThreshold(logisticClassifier)\n",
    "                threshold, optimal_tpr_minus_fpr = logisticClassifier.threshold_from_optimal_f_score(X_test, y_test)\n",
    "\n",
    "                y_predict = logisticClassifier.predict(X_test,threshold)\n",
    "\n",
    "               \n",
    "    elif model_name==\"DecisionTreeClassifier\":\n",
    "                name=\"dt\"\n",
    "                dTreeClassifier = DecisionTreeClassifier()\n",
    "                grid_param = {\n",
    "                    'max_depth': [3,5,10,15,20,30],\n",
    "                    'criterion': ['gini', 'entropy'],\n",
    "                     \"class_weight\":[{1:1.1},{1:1.2},{1:1.2},{1:1.3},{1:1.4},{1:1.5}]\n",
    "                }\n",
    "                gd_sr = GridSearchCV(estimator=dTreeClassifier,\n",
    "                                    param_grid=grid_param,\n",
    "                                    scoring=scoring,\n",
    "                                    cv=cv,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "                gd_sr.fit(X_train, y_train)\n",
    "                best_parameters = gd_sr.best_params_\n",
    "                testTreeClassifier= DecisionTreeClassifier(max_depth=best_parameters[\"max_depth\"], criterion=best_parameters[\"criterion\"])\n",
    "                testTreeClassifier.fit(X_train, y_train)\n",
    "                model=testTreeClassifier\n",
    "                testTreeClassifier=ClassifierWithThreshold(testTreeClassifier)\n",
    "                threshold, optimal_tpr_minus_fpr = testTreeClassifier.threshold_from_optimal_f_score(X_test, y_test)\n",
    "                y_predict = testTreeClassifier.predict(X_test,threshold)\n",
    "              \n",
    "    elif model_name==\"RandomForestClassifier\":\n",
    "                name=\"rf\"\n",
    "                grid_param = {\n",
    "                        'max_depth': [3,5,10,15,20,30],\n",
    "                        'criterion': ['gini', 'entropy'],\n",
    "                        'bootstrap': [True, False],\n",
    "                     \"class_weight\":[{1:1.1},{1:1.2},{1:1.2},{1:1.3},{1:1.4},{1:1.5}]\n",
    "                }\n",
    "\n",
    "                rforestClassifier= RandomForestClassifier()\n",
    "                gd_sr = GridSearchCV(estimator=rforestClassifier,\n",
    "                                            param_grid=grid_param,\n",
    "                                            scoring=scoring,\n",
    "                                            cv=cv,\n",
    "                                            n_jobs=-1)\n",
    "                gd_sr.fit(X_train, y_train)\n",
    "                best_parameters = gd_sr.best_params_\n",
    "        \n",
    "                testforestClassifier= RandomForestClassifier(max_depth=best_parameters[\"max_depth\"], criterion=best_parameters[\"criterion\"], bootstrap= best_parameters[\"bootstrap\"])\n",
    "                \n",
    "                testforestClassifier.fit(X_train, y_train)\n",
    "                model= testforestClassifier\n",
    "                testforestClassifier=ClassifierWithThreshold(testforestClassifier)\n",
    "                threshold, optimal_tpr_minus_fpr = testforestClassifier.threshold_from_optimal_f_score(X_test, y_test)\n",
    "                y_predict = testforestClassifier.predict(X_test,threshold)\n",
    "            \n",
    "\n",
    "\n",
    "    elif model_name == \"SVC\":\n",
    "\n",
    "                name=\"svm\"\n",
    "                svmClassifier = SVC()\n",
    "                grid_param = {\n",
    "                    \"C\": [10**-3,10**-2,10**-1,1,10,100,100],\n",
    "                    'kernel': ['linear', 'poly','rbf','sigmoid']\n",
    "                }\n",
    "                gd_sr = GridSearchCV(estimator=svmClassifier,\n",
    "                                    param_grid=grid_param,\n",
    "                                    scoring=scoring,\n",
    "                                    cv=cv,\n",
    "                                    n_jobs=-1)\n",
    "                gd_sr.fit(X_train, y_train)\n",
    "                best_parameters = gd_sr.best_params_\n",
    "                \n",
    "                testSVMClassifier= SVC(C=best_parameters[\"C\"], kernel=best_parameters[\"kernel\"],probability=True)\n",
    "                testSVMClassifier.fit(X_train, y_train)\n",
    "                model= testSVMClassifier\n",
    "\n",
    "                testSVMClassifier=ClassifierWithThreshold(testSVMClassifier)\n",
    "                threshold, optimal_tpr_minus_fpr = testSVMClassifier.threshold_from_optimal_f_score(X_test, y_test)\n",
    "                y_predict = testSVMClassifier.predict(X_test,threshold)\n",
    "            \n",
    "    elif model_name==\"MLP\":\n",
    "                from keras.layers import LeakyReLU\n",
    "                name=\"mlp\"\n",
    "                model = Sequential()\n",
    "                \n",
    "                \n",
    "                model.add(Dense(120 ,input_dim=ncols-1, activation='relu'))\n",
    "                model.add(Dense(80 ,activation=LeakyReLU(alpha=0.05)))\n",
    "                model.add(Dense(80 ,activation='relu'))\n",
    "                model.add(Dense(40 ,activation='relu'))\n",
    "                model.add(Dense(20 ,activation=LeakyReLU(alpha=0.05)))\n",
    "                model.add(Dense(20 ,activation='relu'))\n",
    "                model.add(Dense(1 ,activation=\"sigmoid\"))\n",
    "                callback =keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "                model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "                model.fit(X_train, y_train,epochs=20,validation_split=0.2,callbacks=[callback])\n",
    "\n",
    "\n",
    "                def threshold_from_optimal_f_score2(X,y,model):\n",
    "                    \n",
    "                        y_pred= model.predict(X)\n",
    "                        fpr, tpr, thresholds = roc_curve(y,np.array(y_pred).squeeze())\n",
    "                        optimal_idx = np.argmax(tpr-fpr)\n",
    "                          \n",
    "                        return thresholds[optimal_idx]\n",
    "                \n",
    "                threshold=threshold_from_optimal_f_score2(X_test,y_test,model)\n",
    "                y_pred= model.predict(X_test)\n",
    "                cnt=0\n",
    "                y_pred_normal= []\n",
    "                for  ii in y_pred:\n",
    "                    if ii>=threshold:\n",
    "                        y_pred_normal.append(1)\n",
    "                        cnt+=1\n",
    "                    else:\n",
    "                        y_pred_normal.append(0)\n",
    "                y_predict=y_pred_normal\n",
    "    return confusion_matrix(y_test,y_predict), model\n",
    "\n",
    "                                \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "def Classification_Report(confusion_matrix):\n",
    "    test_size = sum(sum(confusion_matrix))\n",
    "    accuracy = (confusion_matrix[0][0]+confusion_matrix[1][1])/test_size\n",
    "    precision = confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[0][1])\n",
    "    recall =    confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[1][0])\n",
    "    f1_score= 2*(precision*recall)/(precision+recall)   \n",
    "    \n",
    "    return [accuracy, precision,recall,f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10\n",
    "score_table = np.zeros(shape=(N,4))\n",
    "confM_table = np.zeros(shape=(N,2,2))\n",
    "cwd= os.getcwd()\n",
    "model_folder= cwd+'\\\\'+'hollink_sph_k5_d50_our_models_v2\\\\'\n",
    "model_folder= \"/auto/k2/aykut3/Basic_Level_NLP/emirhan_kod/mills_sph_k5_our_models/\"\n",
    "\n",
    "for r in range(0,N):\n",
    "   rnd=random.randint(0,42)\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15,shuffle=True)\n",
    "   model_name=\"SVC\" # Select the model name\n",
    "   confM,model= ClassificationMethod(X_train, y_train, X_test,y_test,model_name=model_name, cv=10, scoring=\"accuracy\")\n",
    "   print(r)              \n",
    "    #########################################################################\n",
    "    # Save model here, if you would like to save\n",
    "   if model_name == \"MLP\":\n",
    "          filename= model_folder+\"mlp_\"+ str(r+1)\n",
    "          #model.save(filename)\n",
    "   else:\n",
    "     filename= model_folder+\"rf_\"+ str(r+1)+\".pickle\"  # change file naming according to model\n",
    "     #pickle.dump(model, open(filename, 'wb'))\n",
    "    #########################################################################  \n",
    "   aprf=Classification_Report(confM)\n",
    "   confM_table[r,:,:]=confM\n",
    "   score_table[r,:]=aprf\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_table.mean(axis=0)  # average of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you would like to work on the trained model, load and test them. The following script is designed to \n",
    "load weights of the pre-trained model and test on the data.\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variances</th>\n",
       "      <th>average of distances</th>\n",
       "      <th>word_length</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_15</th>\n",
       "      <th>dim_29</th>\n",
       "      <th>dim_30</th>\n",
       "      <th>dim_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.132160</td>\n",
       "      <td>1.230367</td>\n",
       "      <td>0.666691</td>\n",
       "      <td>0.130456</td>\n",
       "      <td>0.357828</td>\n",
       "      <td>0.734222</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.151744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.140866</td>\n",
       "      <td>0.219362</td>\n",
       "      <td>-1.136010</td>\n",
       "      <td>0.363061</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>0.541632</td>\n",
       "      <td>0.383208</td>\n",
       "      <td>0.221336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.648756</td>\n",
       "      <td>-1.158770</td>\n",
       "      <td>0.666691</td>\n",
       "      <td>0.025421</td>\n",
       "      <td>0.584410</td>\n",
       "      <td>0.953403</td>\n",
       "      <td>0.564589</td>\n",
       "      <td>0.359397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.315375</td>\n",
       "      <td>1.397787</td>\n",
       "      <td>-1.136010</td>\n",
       "      <td>0.133144</td>\n",
       "      <td>0.623704</td>\n",
       "      <td>0.871840</td>\n",
       "      <td>0.547083</td>\n",
       "      <td>0.515146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.679824</td>\n",
       "      <td>0.131328</td>\n",
       "      <td>0.924220</td>\n",
       "      <td>0.238872</td>\n",
       "      <td>0.751556</td>\n",
       "      <td>0.437070</td>\n",
       "      <td>0.621916</td>\n",
       "      <td>0.392965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>-0.004329</td>\n",
       "      <td>1.919992</td>\n",
       "      <td>-1.651067</td>\n",
       "      <td>0.295048</td>\n",
       "      <td>0.243623</td>\n",
       "      <td>0.483896</td>\n",
       "      <td>0.149568</td>\n",
       "      <td>0.578824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.011744</td>\n",
       "      <td>1.747807</td>\n",
       "      <td>-1.136010</td>\n",
       "      <td>0.419581</td>\n",
       "      <td>0.397190</td>\n",
       "      <td>0.544186</td>\n",
       "      <td>0.313384</td>\n",
       "      <td>0.689214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1.204477</td>\n",
       "      <td>1.378808</td>\n",
       "      <td>-1.393539</td>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.237050</td>\n",
       "      <td>0.183724</td>\n",
       "      <td>0.182269</td>\n",
       "      <td>0.226344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>-1.049795</td>\n",
       "      <td>0.186689</td>\n",
       "      <td>0.151634</td>\n",
       "      <td>0.423051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781844</td>\n",
       "      <td>0.275958</td>\n",
       "      <td>0.356652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.675658</td>\n",
       "      <td>0.416888</td>\n",
       "      <td>-0.620952</td>\n",
       "      <td>0.305733</td>\n",
       "      <td>0.653475</td>\n",
       "      <td>0.411568</td>\n",
       "      <td>0.185666</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     variances  average of distances  word_length     dim_4    dim_15  \\\n",
       "0    -0.132160              1.230367     0.666691  0.130456  0.357828   \n",
       "1    -0.140866              0.219362    -1.136010  0.363061  0.203963   \n",
       "2    -0.648756             -1.158770     0.666691  0.025421  0.584410   \n",
       "3     0.315375              1.397787    -1.136010  0.133144  0.623704   \n",
       "4    -1.679824              0.131328     0.924220  0.238872  0.751556   \n",
       "..         ...                   ...          ...       ...       ...   \n",
       "513  -0.004329              1.919992    -1.651067  0.295048  0.243623   \n",
       "514   0.011744              1.747807    -1.136010  0.419581  0.397190   \n",
       "515   1.204477              1.378808    -1.393539  0.553086  0.237050   \n",
       "516  -1.049795              0.186689     0.151634  0.423051  0.000000   \n",
       "517   0.675658              0.416888    -0.620952  0.305733  0.653475   \n",
       "\n",
       "       dim_29    dim_30    dim_38  \n",
       "0    0.734222  0.473118  0.151744  \n",
       "1    0.541632  0.383208  0.221336  \n",
       "2    0.953403  0.564589  0.359397  \n",
       "3    0.871840  0.547083  0.515146  \n",
       "4    0.437070  0.621916  0.392965  \n",
       "..        ...       ...       ...  \n",
       "513  0.483896  0.149568  0.578824  \n",
       "514  0.544186  0.313384  0.689214  \n",
       "515  0.183724  0.182269  0.226344  \n",
       "516  0.781844  0.275958  0.356652  \n",
       "517  0.411568  0.185666  1.000000  \n",
       "\n",
       "[518 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data as pandas dataframe, create feature and label data before splitting train and test \n",
    "fname=\"hollink_sph_k5_d50_fs.csv\"\n",
    "data= pd.read_csv(fname,sep=\" \")\n",
    "ncols=len(data.columns)\n",
    "X= data.iloc[:,:ncols-1]\n",
    "y= data.iloc[:,-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_test(path,model_id,N,x_test,Y_test,mode=None):\n",
    "    Score_table = np.zeros(shape=(N,4))\n",
    "    ConfM_table = np.zeros(shape=(N,2,2))\n",
    "    y_pred_avg=0\n",
    "    for r in range(N):\n",
    "            \n",
    "            if mode==\"mlp\":\n",
    "                model_path=path+model_id+str(r+1)\n",
    "                pickled_model = keras.models.load_model(model_path)\n",
    "                def threshold_from_optimal_f_score2(X,y,model):\n",
    "                        \n",
    "                        y_pred= model.predict(X)\n",
    "                        fpr, tpr, thresholds = roc_curve(y,np.array(y_pred).squeeze())\n",
    "\n",
    "                        optimal_idx = np.argmax(tpr-fpr)\n",
    "                        \n",
    "                        return thresholds[optimal_idx], tpr[optimal_idx] - fpr[optimal_idx]\n",
    "               \n",
    "\n",
    "                \n",
    "                threshold,_=threshold_from_optimal_f_score2(X_test,y_test,pickled_model)\n",
    "                y_pred= pickled_model.predict(X_test)\n",
    "                y_pred_avg=y_pred+y_pred_avg\n",
    "                fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred)\n",
    "\n",
    "                 \n",
    "\n",
    "                        \n",
    "                cnt=0\n",
    "                y_pred_normal= []\n",
    "                for  ii in y_pred:\n",
    "                    if ii>=threshold:\n",
    "                        y_pred_normal.append(1)\n",
    "                        cnt+=1\n",
    "                    else:\n",
    "                        y_pred_normal.append(0)\n",
    "                y_predict=y_pred_normal\n",
    "                confM=confusion_matrix(Y_test,y_predict)\n",
    "                aprf=Classification_Report(confM)\n",
    "                ConfM_table[r,:,:]=confM\n",
    "                Score_table[r,:]=aprf    \n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                \n",
    "                model=path+model_id+str(r+1)+\".pickle\"\n",
    "                pickled_model = pickle.load(open(model, 'rb'))\n",
    "                pickled_model =ClassifierWithThreshold(pickled_model )\n",
    "                threshold, optimal_tpr_minus_fpr = pickled_model .threshold_from_optimal_f_score(X_test, y_test)\n",
    "                y_predict = pickled_model .predict(X_test,threshold)\n",
    "                \n",
    "                \n",
    "                \n",
    "                '''\n",
    "                model=path+model_id+str(r+1)+\".pickle\"\n",
    "                pickled_model = pickle.load(open(model, 'rb'))\n",
    "                y_predict=pickled_model.predict(X_test)\n",
    "                '''\n",
    "                confM=confusion_matrix(Y_test,y_predict)\n",
    "                aprf=Classification_Report(confM)\n",
    "                ConfM_table[r,:,:]=confM\n",
    "                Score_table[r,:]=aprf\n",
    "    return aprf, ConfM_table, Score_table,y_pred_avg/N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cwd= os.getcwd()\n",
    "model_folder= cwd+\"/hollink_sph_k5_d50_our_models_v2/\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15,shuffle=True)\n",
    "aprf,confM_table,score_table,y_pred_avg =load_and_test(path=model_folder,x_test=X_test,Y_test=y_test,model_id=\"lr_\",N=10,mode=\"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75      , 0.6       , 0.89189189, 0.7173913 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b66db106c48681de55da5fbed252073da11a1876af7d1ec75c3fbf1c7d64cb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
